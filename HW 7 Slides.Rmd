---
title: "Exponential Distribution"
author: "Abhijith Asok, Chris Hilger, Liam Loscalzo, Katherine Wang"
output: beamer_presentation
theme: "Boadilla"
##colortheme: "structure"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(gridExtra)
set.seed(123)
```

# Point Estimation: Methods

We compared the following point estimators:

- Maximum Likelihood Estimator
- Unbiased correction for the MLE
- Second Method of Moment Estimator

##add criteria for comparing estimators!

# Maximum Likelihood Estimator
```{r}
##code here

```

# Unbiased correction for the MLE
```{r}
##code here
```

# Second Method of Moment Estimator
```{r}
##code here
```

# Confidence Intervals: Methods

We compared the following confidence intervals:

- Wald-based Confidence Interval
- Gamma-based Confidence Interval
- Score-based Confidence Interval
- Bootstrap Confidence Interval

##add criteria for comparing CIs!!

# Wald Confidence Interval

```{r, echo = TRUE}
wald_ci <- function(N, rate, alpha = 0.05){
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  se <- x_bar / sqrt(N)
  ci <- x_bar + c(-1, 1) * qnorm(1 - (alpha / 2))*se
  return(ci)
}
```

# Gamma Confidence Interval

If $X_1, X_2,...,X_n \stackrel{\text{iid}}{\sim} \text{Exponential}(\lambda)$, then

$$
\sum_i^n x_i \sim \text{Gamma}(n, \lambda) \implies \lambda \bar{x} \sim \text{Gamma}(n, n)
$$

Let $g_{y}$ be the $y$th percentile of this distribution. Then we can say:

$$
1 - \alpha = P(g_{\alpha/2} \le \lambda \bar{x} \le g_{1-\alpha/2}) = P(g_{\alpha/2}/\bar{x} \le \lambda \bar{x} \le g_{1-\alpha/2}/\bar{x})
$$

And therefore, a $(1 - \alpha)\%$ confidence interval for $\lambda$ is 

$$
(g_{\alpha / 2}/\bar{x},\, g_{1 - \alpha / 2}/\bar{x})
$$

```{r, echo = FALSE}
gamma_ci <- function(N, rate, alpha = 0.05){
  # Inspiration: https://math.stackexchange.com/questions/1288139/calculate-the-confidence-interval-of-parameter-of-exponential-distribution
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  ci_rate <- qgamma(c(alpha / 2, 1 - (alpha / 2)), N, N) / x_bar
  ci_mean <- 1 / ci_rate
  return(c(min(ci_mean), max(ci_mean)))
}
```

# Score Confidence Interval

For moderate to large sample sizes, the following score statistic is approximately normally distributed

$$
\frac{U(\lambda_o)}{\sqrt{Var[U(\lambda_o)]}} \sim N(0,1)
$$

So the $1-\alpha$ score confidence interval for the mean can be obtained by solving 

$$
\frac{\frac{n}{\lambda_o}-\sum{x_i}}{\sqrt{n/\lambda^2_o}} = \sqrt{n}(1-\lambda_o\overline{X}) \le z_{1-\alpha/2}
$$
for $\overline{X}$, giving us a confidence interval of

$$
\left(\frac{1}{\lambda_o}(1 - \frac{1}{\sqrt{n}}z_{1-\alpha/2}), \frac{1}{\lambda_o}(1 + \frac{1}{\sqrt{n}}z_{1-\alpha/2}) \right)
$$
```{r, echo = FALSE}
score_ci <- function(N, rate, alpha = 0.05) {
  x <- rexp(N, rate = rate)
  xbar <- mean(x)
  ci_rate <- (1 / xbar)*(1 + c(-1, 1) * qnorm(1 - alpha / 2) / sqrt(N))
  ci_mean <- 1 / ci_rate
  return(c(min(ci_mean), max(ci_mean)))
}
```

# Bootstrap Confidence Interval

- Empirical method which does not require knowledge of underlying distribution for $X$
- Based on resampling data (with replacement) many times to create an empirical distribution $U^*$ which approximates the true (unknown) distribution $U$ 
- We estimate the variation of $\bar{x}$ around the true mean $1/\lambda$ using the variation of $\bar{x}^*$ in bootstrapped samples
- As an empirical method, depends on the original data
  - We expect that $\bar{x}^*$ will approximate $\bar{x}$ well, but no guarantee it will be a good estimate of $1/\lambda$
  - Not a problem when we use simulated data

# Bootstrap Confidence Interval
```{r}
bootstrap_ci <- function(N, rate, alpha = 0.05){
  # Function to calculate bootstrap CI
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  # Number of bootstrap samples
  nb <- 1000
  # Take boostrap samples
  bootstrap_samples <- sample(x, N * nb, replace = TRUE) %>%
    matrix(nrow = N, ncol = nb)
  # Get means of columns 
  means <- colMeans(bootstrap_samples)
  # Get deltas (x* - x)
  deltas <- means - x_bar
  deltas <- sort(deltas)
  # Calculate CIs
  ci <- x_bar - quantile(deltas, probs = c(alpha / 2, 1 - (alpha / 2)))
  return(c(mean(ci), max(ci)))
}
```
# Coverage probabilities

```{r, echo = FALSE, message = FALSE}
# Coverage probabilities
coverage_probability <- function(N, rate, ci_fun, alpha = 0.05, B = 1000){
  # Match input function to actual function
  fun <- tryCatch(match.fun(ci_fun), 
                  error = function(e) print(paste0("ci_fun: '", ci_fun, "' does not exist")))
  # Expected value
  exp_val <- 1 / rate
  # Calculate B confidence intervals and put in dataframe
  conf_ints <- replicate(B, fun(N, rate)) %>%
    t() %>% data.frame()
  names(conf_ints) <- c("lower", "upper")
  # Calculate hit rates (expected value inside confidence interval)
  conf_ints <- mutate(conf_ints, hit = (exp_val >= lower & exp_val <= upper))
  coverage <- conf_ints$hit %>% mean()
  return(coverage)
}

lambda <- 1 / 12
beta <- 1 / lambda
n <- 60

# Coverage probability plotting
ns <- seq(1, 500)

###################################################
# I have commented out all of these so that we don't 
# accidentally re run if we don't have to. I've saved 
# the data for coverage probabilities so we can read it 
# in without re-running if not necessary.
###################################################
# Caution: bootstrap takes for-ev-er
# bootstrap_cov <- mclapply(ns, coverage_probability, rate = lambda, ci_fun = "bootstrap_ci") %>% unlist()
# gamma_cov <- mclapply(ns, coverage_probability, rate = lambda, ci_fun = "gamma_ci") %>% unlist()
#wald_cov <- sapply(ns, coverage_probability, rate = lambda, ci_fun = "wald_ci") %>% unlist()
#score_cov <- sapply(ns, coverage_probability, rate = lambda, ci_fun = "score_ci") %>% unlist()
#coverage_df <- data.frame(n = ns, bs = bootstrap_cov, gamma = gamma_cov, wald = wald_cov, score = score_cov)
#write_csv(coverage_df, "./data/coverage_probabilities.csv")
###################################################
# If need to read:
coverage_df <- read_csv("./data/coverage_probabilities.csv")
#coverage_df$score <- score_cov
#coverage_df$wald <- wald_cov

ggplot(coverage_df, aes(x = n, y = bs, color = "Bootstrap")) +
  geom_line() +
  geom_line(aes(x = n, y = gamma, color = "Gamma")) +
  geom_line(aes(x = n, y = wald, color = "Wald")) +
  geom_line(aes(x = n, y = score, color = "Score")) +
  scale_y_continuous(name = "Coverage probability") +
  scale_x_continuous(name = "N") + 
  theme_bw()
```

# Plot CI Widths

```{r}
# need to split
#wald_ci <- function(N, rate, alpha = 0.05){
 # x <- rexp(N, rate = rate)
  #x_bar <- mean(x)
  #se <- sd(x)/sqrt(N)
  #ci <- x_bar + c(-1, 1)*qnorm(1 - (alpha / 2))*se
  #return(ci)
#}
#ggplot() + 
  #stat_function(aes(x = 0:1), fun = wald_ci, args = list(N=10, rate=x))

# width
set.seed(123)
wald_ci_width <- function (N, rate, alpha = 0.05){
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  se <- x_bar / sqrt(N)
  ci <- x_bar + c(-1, 1)*qnorm(1 - (alpha / 2))*se
  width <- ci[2] - ci[1]
  return(width)
}

gamma_ci_width <- function(N, rate, alpha = 0.05){
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  ci_rate <- qgamma(c(alpha / 2, 1 - (alpha / 2)), N, N) / x_bar
  ci_mean <- 1 / ci_rate
  diff <- ci_mean[2] - ci_mean[1]
  return(diff)
}

score_ci_width <- function(N, rate, alpha = 0.05) {
  x <- rexp(N, rate = rate)
  xbar <- mean(x)
  ci <- (1/rate)*(1 + c(-1, 1) * qnorm(1 - alpha / 2) / sqrt(N))
  diff <- ci[2] - ci[1]
  return(diff)
}

bootstrap_ci_width <- function(N, rate, alpha = 0.05){
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  nb <- 1000
  bootstrap_samples <- sample(x, N * nb, replace = TRUE) %>%
    matrix(nrow = N, ncol = nb)
  means <- colMeans(bootstrap_samples)
  deltas <- means - x_bar
  deltas <- sort(deltas)
  ci <- x_bar - quantile(deltas, probs = c(alpha / 2, 1 - (alpha / 2)))
  diff <- ci[2] - ci[1]
  return(diff)
}

set.seed(123)
rate <- seq(0.01, 0.5, 0.01)

wald_width10 <- sapply(rate, FUN = wald_ci_width, N = 10)
gamma_width10 <- sapply(rate, FUN = gamma_ci_width, N = 10)
score_width10 <- sapply(rate, FUN = score_ci_width, N = 10)
bootstrap_width10 <- sapply(rate, FUN = bootstrap_ci_width, N = 10)

wald_width40 <- sapply(rate, FUN = wald_ci_width, N = 40)
gamma_width40 <- sapply(rate, FUN = gamma_ci_width, N = 40)
score_width40 <- sapply(rate, FUN = score_ci_width, N = 40)
bootstrap_width40 <- sapply(rate, FUN = bootstrap_ci_width, N = 40)

dat <- data.frame(lambda = rate, 
                  wald10 = wald_width10,
                  gamma10 = gamma_width10,
                  score10 = score_width10,
                  bootstrap10 = bootstrap_width10,
                  wald40 = wald_width40,
                  gamma40 = gamma_width40,
                  score40 = score_width40,
                  bootstrap40 = bootstrap_width40
                  )
dat <- abs(dat)

p <- ggplot(data = dat, aes(x = lambda)) +
  xlab("Lambda") +
  ylab("CI Width") +
  scale_color_manual("Test", 
                     values=c("dodgerblue",
                              "burlywood",
                              "indianred1",
                              "seagreen"),
                     labels=c("Wald", 
                              "Gamma",
                              "Score",
                              "Bootstrap")) +
  theme_bw()

p10 <- p +
  geom_line(aes(y = wald10, color = "dodgerblue")) +
  geom_line(aes(y = gamma10, color = "burlywood")) +
  geom_line(aes(y = score10, color = "indianred1")) +
  geom_line(aes(y = bootstrap10, color = "seagreen")) +
  ggtitle("CI Widths when N=10")

p40 <- p +
  geom_line(aes(y = wald40, color = "dodgerblue")) +
  geom_line(aes(y = gamma40, color = "burlywood")) +
  geom_line(aes(y = score40, color = "indianred1")) +
  geom_line(aes(y = bootstrap40, color = "seagreen")) +
  ggtitle("CI Widths when N=40")

grid.arrange(p10, p40)

```

# Summary of Findings and Recommendations

```{r cars, echo = TRUE}
summary(cars)
```


