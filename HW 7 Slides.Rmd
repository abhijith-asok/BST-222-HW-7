---
title: "Exponential Distribution"
author: "Abhijith Asok, Chris Hilger, Liam Loscalzo, Katherine Wang"
output: beamer_presentation
theme: "Boadilla"
##colortheme: "structure"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(parallel)
```

# Point Estimation: Methods

We compared the following point estimators:

- Maximum Likelihood Estimator
- Unbiased correction for the MLE
- Second Method of Moment Estimator

##add criteria for comparing estimators!

# Maximum Likelihood Estimator
```{r}
##code here

```

# Unbiased correction for the MLE
```{r}
##code here
```

# Second Method of Moment Estimator
```{r}
##code here
```

# Confidence Intervals: Methods

We compared the following confidence intervals:

- Wald-based Confidence Interval
- Gamma-based Confidence Interval
- Score-based Confidence Interval
- Bootstrap Confidence Interval

##add criteria for comparing CIs!!

# Wald Confidence Interval

```{r, echo = TRUE}
wald_ci <- function(N, rate, alpha = 0.05){
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  se <- x_bar * sqrt(N)
  ci <- x_bar + c(-1, 1)*qnorm(1 - (alpha / 2))*se
  return(ci)
}
```

# Gamma Confidence Interval

If $X_1, X_2,...,X_n \stackrel{\text{iid}}{\sim} \text{Exponential}(\lambda)$, then

$$
\sum_i^n x_i \sim \text{Gamma}(n, \lambda) \implies \lambda \bar{x} \sim \text{Gamma}(n, n)$$

Let $g_{y}$ be the $y$th percentile of this distribution. Then we can say:

$$
1 - \alpha = P(g_{\alpha/2} \le \lambda \bar{x} \le g_{1-\alpha/2}) = P(g_{\alpha/2}/\bar{x} \le \lambda \bar{x} \le g_{1-\alpha/2}/\bar{x})
$$

And therefore, a $(1 - \alpha)\%$ confidence interval for $\lambda$ is 
$$
(g_{\alpha / 2}/\bar{x},\, g_{1 - \alpha / 2}/\bar{x})
$$

```{r, echo = FALSE}
gamma_ci <- function(N, rate, alpha = 0.05){
  # Inspiration: https://math.stackexchange.com/questions/1288139/calculate-the-confidence-interval-of-parameter-of-exponential-distribution
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  ci_rate <- qgamma(c(alpha / 2, 1 - (alpha / 2)), N, N) / x_bar
  ci_mean <- 1 / ci_rate
  return(c(ci_mean[2], ci_mean[1]))
}
```

# Score Confidence Interval

For moderate to large sample sizes, the following score statistic is approximately normally distributed
$$
\frac{U(\lambda_o)}{\sqrt{Var[U(\lambda_o)]}} \sim N(0,1)

$$
So the $1-\alpha$ score confidence interval can be obtained by solving 
$$
\frac{\frac{n}{\lambda_o}-\sum{x_i}}{\sqrt{n/\lambda^2_o}} 
= \sqrt{n}(1-\lambda_o\overline{X}) \le z_{1-\alpha/2}
$$
for $\overline{X}$, giving us a confidence interval of
$$
\def\Xbar{\overline{X}}
\begin{align}
\left(\frac{1}{\lambda_o}(1 - \frac{1}{\sqrt{n}}z_{1-\alpha/2}), \frac{1}{\lambda_o}(1 + \frac{1}{\sqrt{n}}z_{1-\alpha/2}) \right)
\end{align}
$$
```{r, echo = FALSE}
score_ci <- function(N, rate, alpha = 0.05) {
  x <- rexp(N, rate = rate)
  xbar <- mean(x)
  return((1/rate)*(1 + c(-1, 1) * qnorm(1 - alpha / 2) / sqrt(N)))
}

score_ci(100, lambda)
```

# Bootstrap Confidence Interval

- Empirical method which does not require knowledge of underlying distribution for $X$
- Based on resampling data (with replacement) many times to create an empirical distribution $U^*$ which approximates the true (unknown) distribution $U$ 
- We estimate the variation of $\bar{x}$ around the true mean $1/\lambda$ using the variation of $\bar{x}^*$ in bootstrapped samples
- As an empirical method, depends on the original data
  - We expect that $\bar{x}^*$ will approximate $\bar{x}$ well, but no guarantee it will be a good estimate of $1/\lambda$
  - Not a problem when we use simulated data

# Bootstrap Confidence Interval
```{r}
bootstrap_ci <- function(N, rate, alpha = 0.05){
  # Function to calculate bootstrap CI
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  # Number of bootstrap samples
  nb <- 1000
  # Take boostrap samples
  bootstrap_samples <- sample(x, N * nb, replace = TRUE) %>%
    matrix(nrow = N, ncol = nb)
  # Get means of columns 
  means <- colMeans(bootstrap_samples)
  # Get deltas (x* - x)
  deltas <- means - x_bar
  deltas <- sort(deltas)
  # Calculate CIs
  ci <- x_bar - quantile(deltas, probs = c(alpha / 2, 1 - (alpha / 2)))
  return(c(ci[2], ci[1]))
}
```
# Coverage probabilities

```{r, echo = FALSE, message = FALSE}
# Coverage probabilities
library(dplyr)
# Other functions
coverage_probability <- function(N, rate, ci_fun, alpha = 0.05, B = 1000){
  # Match input function to actual function
  fun <- tryCatch(match.fun(ci_fun), 
                  error = function(e) print(paste0("ci_fun: '", ci_fun, "' does not exist")))
  # Expected value
  exp_val <- 1 / rate
  # Calculate B confidence intervals and put in dataframe
  conf_ints <- replicate(B, fun(N, rate)) %>%
    t() %>% data.frame()
  names(conf_ints) <- c("lower", "upper")
  # Calculate hit rates (expected value inside confidence interval)
  conf_ints <- mutate(conf_ints, hit = (exp_val >= lower & exp_val <= upper))
  coverage <- conf_ints$hit %>% mean()
  return(coverage)
}

# Work
set.seed(123)

lambda <- 1 / 12
beta <- 1 / lambda
n <- 60

# Coverage probability plotting
ns <- seq(1, 500)

###################################################
# I have commented out all of these so that we don't 
# accidentally re run if we don't have to. I've saved 
# the data for coverage probabilities so we can read it 
# in without re-running if not necessary.
###################################################
# Caution: bootstrap takes for-ev-er
# bootstrap_cov <- mclapply(ns, coverage_probability, rate = lambda, ci_fun = "bootstrap_ci") %>% unlist()
# gamma_cov <- mclapply(ns, coverage_probability, rate = lambda, ci_fun = "gamma_ci") %>% unlist()
wald_cov <- mclapply(ns, coverage_probability, rate = lambda, ci_fun = "wald_ci") %>% unlist()
score_cov <- mclapply(ns, coverage_probability, rate = lambda, ci_fun = "score_ci") %>% unlist()

#coverage_df <- data.frame(n = ns, bs = bootstrap_cov, gamma = gamma_cov, wald = wald_cov, score = score_cov)
#write_csv(coverage_df, "./data/coverage_probabilities.csv")
###################################################
# If need to read:
coverage_df <- read_csv("./data/coverage_probabilities.csv")

ggplot(coverage_df, aes(x = n, y = bs, color = "Bootstrap")) +
  geom_line() +
  geom_line(aes(x = n, y = gamma, color = "Gamma")) +
  geom_line(aes(x = n, y = wald, color = "Wald")) +
  geom_line(aes(x = n, y = score, color = "Score")) +
  scale_y_continuous(name = "Coverage probability") +
  scale_x_continuous(name = "N")
```

# Plot CI Widths

```{r}
# need to split
#wald_ci <- function(N, rate, alpha = 0.05){
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  se <- sd(x)/sqrt(N)
  ci <- x_bar + c(-1, 1)*qnorm(1 - (alpha / 2))*se
  return(ci)
#}
#ggplot() + 
  #stat_function(aes(x = 0:1), fun = wald_ci, args = list(N=10, rate=x))

# width
wald_ci_width <- function (N, rate, alpha = 0.05){
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  se <- sd(x)/sqrt(N)
  ci <- x_bar + c(-1, 1)*qnorm(1 - (alpha / 2))*se
  width <- ci[2] - ci[1]
  return(width)
}

gamma_ci_width <- function(N, rate, alpha = 0.05){
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  ci_rate <- qgamma(c(alpha / 2, 1 - (alpha / 2)), N, N) / x_bar
  ci_mean <- 1 / ci_rate
  diff <- ci_mean[2] - ci_mean[1]
  return(diff)
}

score_ci_width <- function(N, rate, alpha = 0.05) {
  x <- rexp(N, rate = rate)
  xbar <- mean(x)
  ci <- (1/rate)*(1 + c(-1, 1) * qnorm(1 - alpha / 2) / sqrt(N))
  diff <- ci[2] - ci[1]
  return(diff)
}

bootstrap_ci_width <- function(N, rate, alpha = 0.05){
  x <- rexp(N, rate = rate)
  x_bar <- mean(x)
  nb <- 1000
  bootstrap_samples <- sample(x, N * nb, replace = TRUE) %>%
    matrix(nrow = N, ncol = nb)
  means <- colMeans(bootstrap_samples)
  deltas <- means - x_bar
  deltas <- sort(deltas)
  ci <- x_bar - quantile(deltas, probs = c(alpha / 2, 1 - (alpha / 2)))
  diff <- ci[2] - ci[1]
  return(diff)
}

rate <- seq(0.01, 0.5, 0.01)
wald_width <- sapply(rate, FUN = wald_ci_width, N = 10)
gamma_width <- sapply(rate, FUN = gamma_ci_width, N = 10)
score_width <- sapply(rate, FUN = score_ci_width, N = 10)
bootstrap_width <- sapply(rate, FUN = bootstrap_ci_width, N = 10)
dat <- data.frame(lambda = rate, 
                  wald = wald_width,
                  gamma = gamma_width,
                  score = score_width,
                  bootstrap = bootstrap_width
                  )
ggplot(data = dat, aes(x = lambda)) + 
  geom_line(aes(y = wald, color = "red")) +
  geom_line(aes(y = gamma, color = "dodgerblue")) +
  geom_line(aes(y = score, color = "yellow")) +
  geom_line(aes(y = bootstrap, color = "green")) +
  xlab("Lambda") +
  ylab("CI Width") +
  ggtitle("CI Widths when N=10") +
  scale_color_manual("Test", 
                     values=c("dodgerblue",
                              "seagreen",
                              "burlywood", 
                              "indianred1"),
                     labels=c("Wald", 
                              "Bootstrap",
                              "Gamma",
                              "Score")) +
  theme_bw()

## add other n's
```

# Summary of Findings and Recommendations

```{r cars, echo = TRUE}
summary(cars)
```


